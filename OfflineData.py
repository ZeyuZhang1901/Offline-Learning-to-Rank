import numpy as np
import torch

from PretrainRanker.dataset.Preprocess import PreprocessDataset
from PretrainRanker.Ranker.MDPRankerV2 import MDPRankerV2
from PretrainRanker.Click_Model.CM_model import CM

class OfflineDataset(object):
    '''Generate offline dataset in buffer'''

    def __init__(self,
                hyperparameters,
                dataset,  # labeled dataset, e.g. MQ2007/MQ2008
                memory,  # replay buffer
                log_ranker,  # ranker with logging policy
                click_model) -> None:  # click model to simulate clicks
        self.hyperparameters = hyperparameters
        self.dataset = dataset
        self.memory = memory
        self.click_model = click_model
        self.log_ranker = log_ranker

    def simulation(self,
                qid,  # query id
                end_position):  # end position, either None (search whole list) or int (end at certain position)
        '''simulate clicks on the result list of the query'''

        # result list generated by logging ranker, stable
        result_list = self.log_ranker.get_query_result_list(self.dataset, qid)
        length = len(result_list) if (end_position == None or end_position> len(result_list)) \
            else end_position
        # states, defined as weighted sum of features at previous and current position
        states = np.zeros((length, self.hyperparameters['STATE_DIM']))
        for position in range(length):
            states[position] = states[position-1] * position / (position+1) + \
                self.dataset.get_features_by_query_and_docid(qid, result_list[position])\
                if position > 0 \
                else self.dataset.get_features_by_query_and_docid(qid, result_list[0])

        # generate offline samples in the buffer
        for _ in range(self.hyperparameters['NUM_SAMPLE']):
            # simulate clicks
            clicked_doces, click_labels, propensities, click_start = self.click_model.simulate_cascade(
                                                                        query = qid,
                                                                        result_list = result_list,
                                                                        dataset = self.dataset,
                                                                        k=end_position)
            # fill in the buffer
            candidates = self.dataset.get_all_features_by_query(qid)
            chosen = np.ones(candidates.shape[0])  # one hot binary vector, indicating chosen docs
            for position in range(length):
                # state
                state = np.expand_dims(states[position-1], axis=0) \
                    if position > 0 else np.zeros((1, self.hyperparameters['STATE_DIM']))
                # action
                action = self.dataset.get_features_by_query_and_docid(qid, result_list[position])\
                    .reshape(1,self.hyperparameters['ACTION_DIM'])
                # candidates, delete chosen doc in candidates
                chosen[int(result_list[position])] = 0  # marking chosen docs
                # indices = ((candidates == action[:, None]).sum(axis = 2)\
                #     != candidates.shape[1]).all(axis = 0)
                # candidates = candidates[indices]
                # next state
                next_state = np.expand_dims(states[position], axis=0) 
                # reward
                reward = 1/(np.log2(position+2)*propensities[position]).reshape(1,1)\
                    if click_labels[position] == 1 else np.zeros((1,1))
                
                # push one sample in the buffer
                self.memory.push(torch.tensor(state).to(torch.float32),
                                torch.tensor(action).to(torch.float32),
                                torch.tensor(next_state).to(torch.float32),
                                # torch.tensor(candidates).to(torch.float32),
                                torch.tensor(chosen).to(torch.bool),
                                qid,  # str type
                                torch.tensor(reward).to(torch.float32))
        
    def offlineDataGenerate(self,
                            end_position,
                            queryset):
        '''generate click data for all queries'''
        
        count = 0
        for qid in queryset:
            print(f"\rquery complete: {int(100*count/queryset.shape[0])}%, buffer: {len(self.memory)}/{self.hyperparameters['MEMORY_SIZE']}", end='')
            self.simulation(qid, end_position)
            count += 1


def offlineDataCollect(click_model,
                    hyperparameter,
                    train_set,
                    train_queryset,
                    ranker,
                    memory, 
                    end_position = 10):
    '''Prepare for offline dataset via MDPRanker, the logging policy'''

    model_type = click_model
    # # MQ2007/MQ2008
    # if model_type == "perfect":
    #     pc = [0.0, 0.5, 1.0]
    #     ps = [0.0, 0.0, 0.0]  
    # elif model_type == "navigational":
    #     pc = [0.05, 0.5, 0.95]
    #     ps = [0.2, 0.5, 0.9]
    # elif model_type == "informational":
    #     pc = [0.4, 0.7, 0.9]
    #     ps = [0.1, 0.3, 0.5]

    # MSLR_WEB10K/30K
    if model_type == "perfect":
        pc = [0.0, 0.2, 0.4, 0.8, 1.0]
        ps = [0.0, 0.0, 0.0, 0.0, 0.0]
    elif model_type == "navigational":
        pc = [0.05, 0.3, 0.5, 0.7, 0.95]
        ps = [0.2, 0.3, 0.5, 0.7, 0.9]
    elif model_type == "informational":
        pc = [0.4, 0.6, 0.7, 0.8, 0.9]
        ps = [0.1, 0.2, 0.3, 0.4, 0.5]
    cm = CM(pc, ps)

    print("**********Offline dataset preparation start!**********")
    offlinedataset = OfflineDataset(hyperparameters = hyperparameter,
                                    dataset = train_set,
                                    memory = memory,
                                    log_ranker = ranker,
                                    click_model = cm)

    offlinedataset.offlineDataGenerate(end_position = end_position, 
                                    queryset= train_queryset)
    print("\n**********Offline dataset preparation finish!**********")
